#!/bin/bash -eu

if [ -z "${1:-}" ]; then
	echo "You must pass the file or directory you want to be cached"
	exit 1
else
	CACHE_PATH=$1
	shift
fi

if [ ! -f "$CACHE_PATH" ] && [ ! -d "$CACHE_FILE" ]; then
	echo "$CACHE_PATH should be either a file nor a directory"
	exit 1
fi

if [ -z "${1:-}" ]; then
	echo "You must pass the key to use to identify the cache."
	exit 1
else
	CACHE_KEY=$1
	shift
fi

# Defaults options, will be overridden by getopts if necessary.
SHOULD_FORCE=false
SHOULD_USE_RELATIVE_PATH_IN_TAR=false

while getopts ":fr-" opt; do
	case "${opt}" in
		f)
			SHOULD_FORCE=true
			;;
		r)
			SHOULD_USE_RELATIVE_PATH_IN_TAR=true
			;;
		-)
			case "${OPTARG}" in
				force)
					SHOULD_FORCE=true
					;;
				use_relative_path_in_tar)
					SHOULD_USE_RELATIVE_PATH_IN_TAR=true
					;;
				*)
					echo "Invalid option: --${OPTARG}" >&2
					exit 1
					;;
			esac
			;;
		\?)
			echo "Invalid option: -$OPTARG" >&2
			exit 1
			;;
		:)
			echo "Option -$OPTARG requires an argument." >&2
			exit 1
			;;
	esac
done

S3_BUCKET_NAME=${CACHE_BUCKET_NAME-}
if [ -z "$S3_BUCKET_NAME" ]; then
	if [ -z "$BUILDKITE_PLUGIN_BASH_CACHE_BUCKET" ]; then
		echo "⛔Unable to save file to cache – no \$CACHE_BUCKET_NAME is set"
		exit 1
	else
		echo "Reading bucket name from 'BUILDKITE_PLUGIN_BASH_CACHE_BUCKET'"
		S3_BUCKET_NAME="$BUILDKITE_PLUGIN_BASH_CACHE_BUCKET"
	fi
fi

echo "Using $S3_BUCKET_NAME as cache bucket"

# Use with caution – in general it's not a good idea to overwrite a cache entry
if [[ "$SHOULD_FORCE" == true ]]; then
	echo "Deleting the existing cache key"
	aws s3 rm "s3://$S3_BUCKET_NAME/$CACHE_KEY"
fi

if ! aws s3api head-object --bucket "$S3_BUCKET_NAME" --key "$CACHE_KEY" > /dev/null 2>&1; then
	echo "No existing cache entry for $CACHE_KEY – storing in cache"

	echo "	Compressing"
	if [[ "$SHOULD_USE_RELATIVE_PATH_IN_TAR" == true ]]; then
		# This is used by actions such as `install_swiftpm_dependencies`
		# This configuration allows the tar to not include the full system path of the
		# directory that's being archived. For example, this will save only the
		# "DIRECTORY_BEING_ARCHIVED" in `/User/builder/DIRECTORY_BEING_ARCHIVED`
		# instead of also creating `/User/builder` when extracting the archive
		tar -czf "$CACHE_KEY" --directory "$CACHE_PATH" .
	else
		tar -czf "$CACHE_KEY" "$CACHE_PATH"
	fi

	echo "	Uploading"
	# If the bucket has transfer acceleration enabled, use it!
	ACCELERATION_STATUS=$(aws s3api get-bucket-accelerate-configuration --bucket "$S3_BUCKET_NAME" | jq '.Status' -r || true)

	if [ "$ACCELERATION_STATUS" = "Enabled" ]; then
		echo "Uploading with transfer acceleration"
		aws s3 cp "$CACHE_KEY" "s3://$S3_BUCKET_NAME/$CACHE_KEY" --quiet --endpoint-url https://s3-accelerate.amazonaws.com
	else
		aws s3 cp "$CACHE_KEY" "s3://$S3_BUCKET_NAME/$CACHE_KEY" --quiet
	fi

	echo "	Cleaning Up"
	rm "$CACHE_KEY"
else
	echo "This file is already cached – skipping upload"
fi
